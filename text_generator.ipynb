{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "hPzIpU1DU-lt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-FOVcGmVlib",
        "outputId": "e9d08bd8-8fdd-463a-e9c5-67f780f9093c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, x_data, y_data):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data"
      ],
      "metadata": {
        "id": "EjjHAnm8GPlR"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def __len__(self):\n",
        "        return len(self.x_data)"
      ],
      "metadata": {
        "id": "EZenQJFFVllt"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.x_data[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.y_data[idx], dtype=torch.long)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "AlgbDiVhVlo7"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        text = f.read()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "NwNcGKvOVlrn"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_words(text):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text.lower())\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "vqwvkccIVluE"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_text_to_numbers(text, chars):\n",
        "    char_to_num = dict((c, i) for i, c in enumerate(chars))\n",
        "    return [char_to_num[char] for char in text]\n"
      ],
      "metadata": {
        "id": "AsL73LMVVlw_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, chars, num_to_char, pattern, vocab_len):\n",
        "    for i in range(1000):\n",
        "        x = torch.tensor(pattern, dtype=torch.float32).unsqueeze(0)\n",
        "        x = x.view(-1, 100, 1)\n",
        "        x = x / float(vocab_len)\n",
        "        prediction = model(x)\n",
        "        index = torch.argmax(prediction)\n",
        "        result = num_to_char[index.item()]\n",
        "        seq_in = [num_to_char[value] for value in pattern]\n",
        "        print(result, end=\"\")\n",
        "        pattern.append(index.item())\n",
        "        pattern = pattern[1:len(pattern)]"
      ],
      "metadata": {
        "id": "vEFc3B26VlzP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  file_path = '/content/gdrive/MyDrive/frankenstein.txt'\n",
        "  text = load_data(file_path)\n",
        "  processed_inputs = tokenize_words(text)\n",
        "  chars = sorted(list(set(processed_inputs)))\n",
        "  vocab_len = len(chars)\n",
        "  char_to_num = dict((c, i) for i, c in enumerate(chars))\n",
        "  num_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "  seq_length = 100\n",
        "  x_data = []\n",
        "  y_data = []\n",
        "  for i in range(0, len(processed_inputs) - seq_length, 1):\n",
        "    in_seq = processed_inputs[i:i + seq_length]\n",
        "    out_seq = processed_inputs[i + seq_length]\n",
        "    x_data.append([char_to_num[char] for char in in_seq])\n",
        "    y_data.append(char_to_num[out_seq])\n",
        "  dataset = TextDataset(x_data, y_data)\n",
        "  data_loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "  class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_len):\n",
        "      super(LSTMModel, self).__init__()\n",
        "      self.lstm = nn.LSTM(input_size=1, hidden_size=256, num_layers=1, batch_first=True)\n",
        "      self.dropout = nn.Dropout(0.2)\n",
        "      self.fc = nn.Linear(256, vocab_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, 100, 1)\n",
        "      h0 = torch.zeros(1, x.size(0), 256).to(x.device)\n",
        "      c0 = torch.zeros(1, x.size(0), 256).to(x.device)\n",
        "      out, _ = self.lstm(x, (h0, c0))\n",
        "      out = self.dropout(out[:, -1, :])\n",
        "      out = self.fc(out)\n",
        "      return out\n",
        "\n",
        "  model = LSTMModel(vocab_len)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  for epoch in range(2):\n",
        "    for batch in data_loader:\n",
        "      inputs, labels = batch\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "  start = np.random.randint(0, len(x_data) - 1)\n",
        "  pattern = x_data[start]\n",
        "  print(\"Random Seed:\")\n",
        "  print(\" \", ''.join([num_to_char[value] for value in pattern]), \"\")\n",
        "  generate_text(model, chars, num_to_char, pattern, vocab_len)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "LZdgbcPjHWmR",
        "outputId": "0c00116d-8af9-4722-be63-7d5c6a43d5ce"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'TextDataset' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-d4ef11aca06a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_to_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-75-d4ef11aca06a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0my_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_to_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    161\u001b[0m             )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             raise ValueError(\n\u001b[1;32m    165\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36mnum_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# dataset size might change at runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'TextDataset' has no len()"
          ]
        }
      ]
    }
  ]
}